{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb1c1f8",
   "metadata": {},
   "source": [
    "## Part 1 - Produce Data\n",
    "We elected to use the datagen connector to generate fake data for this assignment. The topic we used was 'stocktrades. The steps were as follows:\n",
    "*  Open a browser and go to http://localhost:9021/\n",
    "*  Select the available cluster\n",
    "*  On the menu bar, select Connect\n",
    "*  Click on the connect-default cluster in the Connect Clusters list.\n",
    "*  Click on Add connector\n",
    "*  Select DatagenConnector\n",
    "*  Enter connector_stock_trades in the Name field\n",
    "\n",
    "Then:\n",
    "Generate a data stream with following configurations:\n",
    "```\n",
    "Key converter class: org.apache.kafka.connect.storage.StringConverter\n",
    "kafka.topic: stocktrades\n",
    "max.interval: 100\n",
    "quickstart: Stock_Trades\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43f3f4",
   "metadata": {},
   "source": [
    "## Part 2 - Using Ksql to create at least 2 streams with filtering from topics\n",
    "\n",
    "To begin, you need to create a stream called stocktrades with no filtering in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252943b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE STREAM STOCKTRADES\n",
    "   (SIDE STRING, QUANTITY INTEGER, SYMBOL STRING, PRICE INTEGER, ACCOUNT STRING, USERID STRING)\n",
    "       WITH (KAFKA_TOPIC='stocktrades', VALUE_FORMAT='AVRO');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31402a79",
   "metadata": {},
   "source": [
    "### Stream 1 - Sell Stream\n",
    "It may be in the interest of the business to view only streams where the stock was sold and not bought. This would be useful in identifying which shares should be taken as a 'short' position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0954e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE STREAM SELL_TRADES WITH (KAFKA_TOPIC='SELL_TRADES', PARTITIONS=1, REPLICAS=1) AS SELECT\n",
    "  STOCKTRADES.QUANTITY QUANTITY,\n",
    "  STOCKTRADES.SYMBOL SYMBOL,\n",
    "  STOCKTRADES.PRICE PRICE,\n",
    "  STOCKTRADES.ACCOUNT ACCOUNT,\n",
    "  STOCKTRADES.USERID USERID\n",
    "FROM STOCKTRADES STOCKTRADES\n",
    "WHERE (STOCKTRADES.SIDE = 'SELL')\n",
    "EMIT CHANGES;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d3a77",
   "metadata": {},
   "source": [
    "### Stream 2 - Buy Stream\n",
    "It may also be interesting to the business to see trades that were large buys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e993ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE STREAM BUY_TRADES WITH (KAFKA_TOPIC='BUY_TRADES', PARTITIONS=1, REPLICAS=1) AS SELECT\n",
    "  STOCKTRADES.QUANTITY QUANTITY,\n",
    "  STOCKTRADES.SYMBOL SYMBOL,\n",
    "  STOCKTRADES.PRICE PRICE,\n",
    "  STOCKTRADES.ACCOUNT ACCOUNT,\n",
    "  STOCKTRADES.USERID USERID\n",
    "FROM STOCKTRADES STOCKTRADES\n",
    "WHERE (STOCKTRADES.SIDE = 'BUY')\n",
    "EMIT CHANGES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bdaa72",
   "metadata": {},
   "source": [
    "### Table 1 - Aggregated Buy Trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE AGG_BUY_ORDERS WITH (KAFKA_TOPIC='AGG_BUY_ORDERS', PARTITIONS=1, REPLICAS=1) AS SELECT\n",
    "  BUY_TRADES.SYMBOL SYMBOL,\n",
    "  SUM(BUY_TRADES.QUANTITY) QUANTITY_AGG,\n",
    "  AVG(BUY_TRADES.PRICE) PRICE_AVG,\n",
    "  SUM((BUY_TRADES.QUANTITY * BUY_TRADES.PRICE)) VALUE_TRADED\n",
    "FROM BUY_TRADES BUY_TRADES\n",
    "WINDOW TUMBLING ( SIZE 60 SECONDS )\n",
    "GROUP BY BUY_TRADES.SYMBOL\n",
    "EMIT CHANGES;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350b7a1",
   "metadata": {},
   "source": [
    "### Table 2 - Aggregated Sell Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE AGG_SELL_ORDERS WITH (KAFKA_TOPIC='AGG_SELL_ORDERS', PARTITIONS=1, REPLICAS=1) AS SELECT\n",
    "  SELL_TRADES.SYMBOL SYMBOL,\n",
    "  SUM(SELL_TRADES.QUANTITY) QUANTITY_AGG,\n",
    "  AVG(SELL_TRADES.PRICE) PRICE_AVG,\n",
    "  SUM((SELL_TRADES.QUANTITY * SELL_TRADES.PRICE)) VALUE_TRADED\n",
    "FROM SELL_TRADES SELL_TRADES\n",
    "WINDOW TUMBLING ( SIZE 60 SECONDS )\n",
    "GROUP BY SELL_TRADES.SYMBOL\n",
    "EMIT CHANGES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8209b0a7",
   "metadata": {},
   "source": [
    "## Part 3 - Consume/Transform data with Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e928a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b4433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName('kafka') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39caff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ecebe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._jvm.org.apache.hadoop.util.VersionInfo.getVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa70750",
   "metadata": {},
   "source": [
    "## Raw Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d09f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"subscribe\", \"stocktrades\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b147227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c06efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stream = stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"raw_stocktrades_view\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe330b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
