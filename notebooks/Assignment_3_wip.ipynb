{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb7aacc",
   "metadata": {},
   "source": [
    "## Part 1 - Produce Data\n",
    "We elected to use the datagen connector to generate fake data for this assignment. The topic we used was 'stocktrades. The steps were as follows:\n",
    "*  Open a browser and go to http://localhost:9021/\n",
    "*  Select the available cluster\n",
    "*  On the menu bar, select Connect\n",
    "*  Click on the connect-default cluster in the Connect Clusters list.\n",
    "*  Click on Add connector\n",
    "*  Select DatagenConnector\n",
    "*  Enter connector_stock_trades in the Name field\n",
    "\n",
    "Then:\n",
    "Generate a data stream with following configurations:\n",
    "```\n",
    "{\n",
    "  \"name\": \"connector_stock_trades\",\n",
    "  \"connector.class\": \"io.confluent.kafka.connect.datagen.DatagenConnector\",\n",
    "  \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n",
    "  \"kafka.topic\": \"stocktrades\",\n",
    "  \"max.interval\": \"100\",\n",
    "  \"quickstart\": \"Stock_Trades\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7a1a8",
   "metadata": {},
   "source": [
    "## Part 2 - Using Ksql to create at least 2 streams with filtering from topics\n",
    "\n",
    "To begin, you need to create a stream called stocktrades with no filtering in place."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3786d15",
   "metadata": {},
   "source": [
    "CREATE STREAM STOCKTRADES\n",
    "   (SIDE STRING, QUANTITY INTEGER, SYMBOL STRING, PRICE INTEGER, ACCOUNT STRING, USERID STRING)\n",
    "       WITH (KAFKA_TOPIC='stocktrades', VALUE_FORMAT='AVRO');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee2ce3",
   "metadata": {},
   "source": [
    "### Create JSON Stream\n",
    "In order for this to play nicely with spark, we need to mimic the raw stream as a json formatted stream."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e60d17a",
   "metadata": {},
   "source": [
    "CREATE STREAM STOCKTRADES_JSON WITH (KAFKA_TOPIC='STOCKTRADES_JSON', VALUE_FORMAT='JSON') AS SELECT\n",
    "* FROM STOCKTRADES STOCKTRADES\n",
    "EMIT CHANGES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389264db",
   "metadata": {},
   "source": [
    "### Stream 1 - Sell Stream\n",
    "It may be in the interest of the business to view only streams where the stock was sold and not bought. This would be useful in identifying which shares should be taken as a 'short' position"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea4e9410",
   "metadata": {},
   "source": [
    "CREATE STREAM SELL_TRADES WITH (KAFKA_TOPIC='SELL_TRADES', VALUE_FORMAT='JSON') AS SELECT\n",
    "  STOCKTRADES_JSON.QUANTITY QUANTITY,\n",
    "  STOCKTRADES_JSON.SYMBOL SYMBOL,\n",
    "  STOCKTRADES_JSON.PRICE PRICE,\n",
    "  STOCKTRADES_JSON.ACCOUNT ACCOUNT,\n",
    "  STOCKTRADES_JSON.USERID USERID\n",
    "FROM STOCKTRADES_JSON STOCKTRADES_JSON\n",
    "WHERE (STOCKTRADES_JSON.SIDE = 'SELL')\n",
    "EMIT CHANGES;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70439265",
   "metadata": {},
   "source": [
    "### Stream 2 - Buy Stream\n",
    "It may also be interesting to the business to see trades that were large buys."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed62c3b8",
   "metadata": {},
   "source": [
    "CREATE STREAM BUY_TRADES WITH (KAFKA_TOPIC='BUY_TRADES', VALUE_FORMAT='JSON') AS SELECT\n",
    "  STOCKTRADES_JSON.QUANTITY QUANTITY,\n",
    "  STOCKTRADES_JSON.SYMBOL SYMBOL,\n",
    "  STOCKTRADES_JSON.PRICE PRICE,\n",
    "  STOCKTRADES_JSON.ACCOUNT ACCOUNT,\n",
    "  STOCKTRADES_JSON.USERID USERID\n",
    "FROM STOCKTRADES_JSON STOCKTRADES_JSON\n",
    "WHERE (STOCKTRADES_JSON.SIDE = 'BUY')\n",
    "EMIT CHANGES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c5915",
   "metadata": {},
   "source": [
    "### Table 1 - Aggregated Buy Trades\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e503e550",
   "metadata": {},
   "source": [
    "CREATE TABLE AGG_BUY_ORDERS WITH (KAFKA_TOPIC='AGG_BUY_ORDERS', VALUE_FORMAT='JSON') AS SELECT\n",
    "  BUY_TRADES.SYMBOL SYMBOL,\n",
    "  SUM(BUY_TRADES.QUANTITY) QUANTITY_AGG,\n",
    "  AVG(BUY_TRADES.PRICE) PRICE_AVG,\n",
    "  SUM((BUY_TRADES.QUANTITY * BUY_TRADES.PRICE)) VALUE_TRADED\n",
    "FROM BUY_TRADES BUY_TRADES\n",
    "WINDOW TUMBLING ( SIZE 60 SECONDS )\n",
    "GROUP BY BUY_TRADES.SYMBOL\n",
    "EMIT CHANGES;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97673b15",
   "metadata": {},
   "source": [
    "### Table 2 - Aggregated Sell Trades"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fbc5b46",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "CREATE TABLE AGG_SELL_ORDERS WITH (KAFKA_TOPIC='AGG_SELL_ORDERS', VALUE_FORMAT='JSON') AS SELECT\n",
    "  SELL_TRADES.SYMBOL SYMBOL,\n",
    "  SUM(SELL_TRADES.QUANTITY) QUANTITY_AGG,\n",
    "  AVG(SELL_TRADES.PRICE) PRICE_AVG,\n",
    "  SUM((SELL_TRADES.QUANTITY * SELL_TRADES.PRICE)) VALUE_TRADED\n",
    "FROM SELL_TRADES SELL_TRADES\n",
    "WINDOW TUMBLING ( SIZE 60 SECONDS )\n",
    "GROUP BY SELL_TRADES.SYMBOL\n",
    "EMIT CHANGES;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945762b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3 - Consume/Transform data with Spark Streaming\n",
    "\n",
    "### Set up Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efad3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType,StringType, StructField, IntegerType, FloatType, BinaryType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2048050",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName('kafka') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18249d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336512c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._jvm.org.apache.hadoop.util.VersionInfo.getVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213f973",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building a Stream\n",
    "The code below just walks through how the stream is built. A streamlined function is built for part 3a below.\n",
    "\n",
    "Firstly, we need to connect to our raw JSON stream 'STOCKTRADES_JSON'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67425914",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"subscribe\", \"STOCKTRADES_JSON\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610da045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad72c7",
   "metadata": {},
   "source": [
    "create a stream to view the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d33a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stream = stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"raw_stocktrades_view\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4aa9fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "|null|[7B 22 53 49 44 4...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT key, value FROM raw_stocktrades_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6885c",
   "metadata": {},
   "source": [
    "Despite the key being NULL, the key is equivalent to the `value.symbol` field as shown in confluent. We are happy to proceed without this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6934d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc6b97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert Key Value pairs to strings\n",
    "Converting to strings allows us to read the actual content of the key and value. Above the values are in hexadecimal binary, which doesnt make sesne to a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdb9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_stream_df = stream_df \\\n",
    "    .withColumn(\"key\", stream_df[\"key\"].cast(StringType())) \\\n",
    "      .withColumn('value', stream_df[\"value\"].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc0464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_stream = string_stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"string_stocktrades_view\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb8a467",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"SELL\",\"Q...|\n",
      "|null|{\"SIDE\":\"BUY\",\"QU...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT key, value FROM string_stocktrades_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb8a2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb6512",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformation\n",
    "\n",
    "For future parts, we will need the data in a tidy format, not a JSON format. To do this, we need to outline the JSON structure of the data. and use the inbuilt `from_json` function from Spark to read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1266278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_stocktrades =  StructType([\n",
    "        StructField(\"SIDE\", StringType(),  True),\n",
    "        StructField(\"QUANTITY\", IntegerType(),  True),\n",
    "        StructField(\"PRICE\", IntegerType(),  True),\n",
    "        StructField(\"SYMBOL\", StringType(),  True),\n",
    "        StructField(\"ACCOUNT\", StringType(), True),\n",
    "         StructField(\"USERID\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d790764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_stream_df = string_stream_df\\\n",
    "    .withColumn(\"value\", F.from_json(\"value\", schema_stocktrades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab8af613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- SIDE: string (nullable = true)\n",
      " |    |-- QUANTITY: integer (nullable = true)\n",
      " |    |-- PRICE: integer (nullable = true)\n",
      " |    |-- SYMBOL: string (nullable = true)\n",
      " |    |-- ACCOUNT: string (nullable = true)\n",
      " |    |-- USERID: string (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86f0505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_stream = json_stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"extract_stocktrades_view\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3b1d5ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------+----------------+---------+------+-----------------------+-------------+\n",
      "|key |value                                   |topic           |partition|offset|timestamp              |timestampType|\n",
      "+----+----------------------------------------+----------------+---------+------+-----------------------+-------------+\n",
      "|null|{BUY, 1934, 893, ZTEST, ABC123, User_8} |STOCKTRADES_JSON|0        |0     |2021-06-11 00:40:34.802|0            |\n",
      "|null|{SELL, 1401, 379, ZVV, ABC123, User_4}  |STOCKTRADES_JSON|0        |1     |2021-06-11 00:40:34.837|0            |\n",
      "|null|{SELL, 2310, 848, ZJZZT, LMN456, User_6}|STOCKTRADES_JSON|0        |2     |2021-06-11 00:40:34.897|0            |\n",
      "|null|{BUY, 35, 845, ZWZZT, LMN456, User_2}   |STOCKTRADES_JSON|0        |3     |2021-06-11 00:40:34.989|0            |\n",
      "|null|{BUY, 3883, 503, ZBZX, ABC123, User_8}  |STOCKTRADES_JSON|0        |4     |2021-06-11 00:40:35.077|0            |\n",
      "|null|{SELL, 2137, 88, ZWZZT, ABC123, User_5} |STOCKTRADES_JSON|0        |5     |2021-06-11 00:40:35.108|0            |\n",
      "|null|{BUY, 3459, 21, ZBZX, XYZ789, User_6}   |STOCKTRADES_JSON|0        |6     |2021-06-11 00:40:35.138|0            |\n",
      "|null|{BUY, 828, 253, ZBZX, XYZ789, User_5}   |STOCKTRADES_JSON|0        |7     |2021-06-11 00:40:35.206|0            |\n",
      "|null|{SELL, 3058, 791, ZVV, LMN456, User_7}  |STOCKTRADES_JSON|0        |8     |2021-06-11 00:40:35.293|0            |\n",
      "|null|{SELL, 937, 399, ZXZZT, ABC123, User_6} |STOCKTRADES_JSON|0        |9     |2021-06-11 00:40:35.346|0            |\n",
      "|null|{SELL, 1856, 348, ZBZX, LMN456, User_9} |STOCKTRADES_JSON|0        |10    |2021-06-11 00:40:35.374|0            |\n",
      "|null|{SELL, 3680, 168, ZBZX, XYZ789, User_1} |STOCKTRADES_JSON|0        |11    |2021-06-11 00:40:35.459|0            |\n",
      "|null|{SELL, 3488, 920, ZTEST, LMN456, User_6}|STOCKTRADES_JSON|0        |12    |2021-06-11 00:40:35.473|0            |\n",
      "|null|{SELL, 1134, 690, ZBZX, XYZ789, User_9} |STOCKTRADES_JSON|0        |13    |2021-06-11 00:40:35.495|0            |\n",
      "|null|{BUY, 4767, 657, ZWZZT, ABC123, User_9} |STOCKTRADES_JSON|0        |14    |2021-06-11 00:40:35.565|0            |\n",
      "|null|{BUY, 2685, 662, ZWZZT, XYZ789, User_2} |STOCKTRADES_JSON|0        |15    |2021-06-11 00:40:35.57 |0            |\n",
      "|null|{SELL, 4504, 822, ZVZZT, XYZ789, User_7}|STOCKTRADES_JSON|0        |16    |2021-06-11 00:40:35.617|0            |\n",
      "|null|{SELL, 1806, 194, ZTEST, ABC123, User_3}|STOCKTRADES_JSON|0        |17    |2021-06-11 00:40:35.638|0            |\n",
      "|null|{SELL, 4687, 882, ZJZZT, LMN456, User_9}|STOCKTRADES_JSON|0        |18    |2021-06-11 00:40:35.735|0            |\n",
      "|null|{BUY, 4561, 428, ZJZZT, XYZ789, User_9} |STOCKTRADES_JSON|0        |19    |2021-06-11 00:40:35.789|0            |\n",
      "+----+----------------------------------------+----------------+---------+------+-----------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT * FROM extract_stocktrades_view').show(20, False))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d70701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d07b3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Flatten Data\n",
    "Finally, we need to separate the data that is in the value field into individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea54631",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrades_stream_df = json_stream_df \\\n",
    "    .select( \\\n",
    "        F.col(\"key\").alias(\"event_key\"), \\\n",
    "        F.col(\"topic\").alias(\"event_topic\"), \\\n",
    "        F.col(\"timestamp\").alias(\"event_timestamp\"), \\\n",
    "        \"value.side\", \\\n",
    "        \"value.quantity\", \\\n",
    "        \"value.price\", \\\n",
    "        \"value.symbol\", \\\n",
    "        \"value.account\", \\\n",
    "        \"value.userid\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc85ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_key: string (nullable = true)\n",
      " |-- event_topic: string (nullable = true)\n",
      " |-- event_timestamp: timestamp (nullable = true)\n",
      " |-- side: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- userid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocktrades_stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrades_stream = stocktrades_stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"stocktrades_view\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0d44d47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|event_key|     event_topic|     event_timestamp|side|quantity|price|symbol|account|userid|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    1934|  893| ZTEST| ABC123|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    1401|  379|   ZVV| ABC123|User_4|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    2310|  848| ZJZZT| LMN456|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|      35|  845| ZWZZT| LMN456|User_2|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    3883|  503|  ZBZX| ABC123|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    2137|   88| ZWZZT| ABC123|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    3459|   21|  ZBZX| XYZ789|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|     828|  253|  ZBZX| XYZ789|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    3058|  791|   ZVV| LMN456|User_7|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|     937|  399| ZXZZT| ABC123|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    1856|  348|  ZBZX| LMN456|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    3680|  168|  ZBZX| XYZ789|User_1|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    3488|  920| ZTEST| LMN456|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    1134|  690|  ZBZX| XYZ789|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    4767|  657| ZWZZT| ABC123|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    2685|  662| ZWZZT| XYZ789|User_2|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    4504|  822| ZVZZT| XYZ789|User_7|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    1806|  194| ZTEST| ABC123|User_3|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...|SELL|    4687|  882| ZJZZT| LMN456|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 00:40:...| BUY|    4561|  428| ZJZZT| XYZ789|User_9|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT * FROM stocktrades_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a242c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrades_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d4ac6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3a - Build at least 2 Spark Streaming dataframes\n",
    "This function generates a stream from stocktrades with one line of code so its easier to call in later components. It is equivalent to the structure outlined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b0a61b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_stocktrades_stream(keep_stream = False):\n",
    "    \n",
    "    # Define the raw Spark Stream\n",
    "    stream_df = spark \\\n",
    "      .readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "      .option(\"startingOffsets\", \"latest\") \\\n",
    "      .option(\"subscribe\", \"STOCKTRADES_JSON\") \\\n",
    "      .load()\n",
    "    \n",
    "    # Convert to string types for JSON conversion\n",
    "    string_stream_df = stream_df \\\n",
    "        .withColumn(\"key\", stream_df[\"key\"].cast(StringType())) \\\n",
    "        .withColumn('value', stream_df[\"value\"].cast(StringType()))\n",
    "    \n",
    "    # Define the Schema for the end JSON format\n",
    "    schema_stocktrades =  StructType([\n",
    "        StructField(\"SIDE\", StringType(),  True),\n",
    "        StructField(\"QUANTITY\", IntegerType(),  True),\n",
    "        StructField(\"PRICE\", IntegerType(),  True),\n",
    "        StructField(\"SYMBOL\", StringType(),  True),\n",
    "        StructField(\"ACCOUNT\", StringType(), True),\n",
    "        StructField(\"USERID\", StringType(), True)\n",
    "])\n",
    "    # Convert the string type to json format stream\n",
    "    json_stream_df = string_stream_df\\\n",
    "    .withColumn(\"value\", F.from_json(\"value\", schema_stocktrades))\n",
    "    stocktrades_stream_df = json_stream_df \\\n",
    "    .select( \\\n",
    "        F.col(\"key\").alias(\"event_key\"), \\\n",
    "        F.col(\"topic\").alias(\"event_topic\"), \\\n",
    "        F.col(\"timestamp\").alias(\"event_timestamp\"), \\\n",
    "        \"value.side\", \\\n",
    "        \"value.quantity\", \\\n",
    "        \"value.price\", \\\n",
    "        \"value.symbol\", \\\n",
    "        \"value.account\", \\\n",
    "        \"value.userid\"\n",
    "    )\n",
    "    \n",
    "    # Export a queryable view od the stream\n",
    "    \n",
    "    if not keep_stream:\n",
    "        return stocktrades_stream_df \\\n",
    "        .writeStream \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"stocktrades_view\") \\\n",
    "        .start()\n",
    "    else:\n",
    "        return stocktrades_stream_df \\\n",
    "        .writeStream \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"stocktrades_view\") \\\n",
    "        .start(), stocktrades_stream_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c608fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrades_stream = generate_stocktrades_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9807b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|event_key|     event_topic|     event_timestamp|side|quantity|price|symbol|account|userid|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    1257|  877|   ZVV| XYZ789|User_4|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    4221|  995| ZXZZT| LMN456|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    3693|  551| ZJZZT| XYZ789|User_3|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    4476|  395| ZJZZT| ABC123|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|     578|  207| ZXZZT| XYZ789|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    1865|  452| ZJZZT| LMN456|User_7|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|     114|  888| ZXZZT| ABC123|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|     574|  996|  ZBZX| ABC123|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    1483|  938|  ZBZX| XYZ789|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    1045|  956| ZVZZT| XYZ789|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    3260|  367|   ZVV| LMN456|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    4685|   98| ZJZZT| XYZ789|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|     789|  938|   ZVV| ABC123|User_9|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    1653|  964|  ZBZX| ABC123|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    3500|  810| ZXZZT| LMN456|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    3834|   60|   ZVV| LMN456|User_3|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    1653|  558|   ZVV| ABC123|User_1|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    4365|  738|  ZBZX| ABC123|User_7|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...|SELL|    3801|  229| ZJZZT| ABC123|User_3|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:00:...| BUY|    1009|  760|   ZVV| ABC123|User_6|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT * FROM stocktrades_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d62b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrades_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8194b8",
   "metadata": {},
   "source": [
    "### Second Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daabb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to stream filtered streams from Kafka as streaming dataframes\n",
    "def generate_side_stream(SIDE):\n",
    "    \n",
    "    # Create string for source\n",
    "    source_stream = SIDE + \"_TRADES\"\n",
    "    # Define the raw Spark Stream\n",
    "    \n",
    "    stream_df = spark \\\n",
    "      .readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "      .option(\"startingOffsets\", \"latest\") \\\n",
    "      .option(\"subscribe\", source_stream) \\\n",
    "      .load()\n",
    "    \n",
    "    # Convert to string types for JSON conversion\n",
    "    string_stream_df = stream_df \\\n",
    "        .withColumn(\"key\", stream_df[\"key\"].cast(StringType())) \\\n",
    "        .withColumn('value', stream_df[\"value\"].cast(StringType()))\n",
    "    \n",
    "    # Define the Schema for the end JSON format\n",
    "    schema_stocktrades =  StructType([\n",
    "        StructField(\"QUANTITY\", IntegerType(),  True),\n",
    "        StructField(\"PRICE\", IntegerType(),  True),\n",
    "        StructField(\"SYMBOL\", StringType(),  True),\n",
    "        StructField(\"ACCOUNT\", StringType(), True),\n",
    "        StructField(\"USERID\", StringType(), True)\n",
    "])\n",
    "    # Convert the string type to json format stream\n",
    "    json_stream_df = string_stream_df\\\n",
    "    .withColumn(\"value\", F.from_json(\"value\", schema_stocktrades))\n",
    "    stocktrades_stream_df = json_stream_df \\\n",
    "    .select( \\\n",
    "        F.col(\"key\").alias(\"event_key\"), \\\n",
    "        F.col(\"topic\").alias(\"event_topic\"), \\\n",
    "        F.col(\"timestamp\").alias(\"event_timestamp\"), \\\n",
    "        \"value.quantity\", \\\n",
    "        \"value.price\", \\\n",
    "        \"value.symbol\", \\\n",
    "        \"value.account\", \\\n",
    "        \"value.userid\"\n",
    "    )\n",
    "    \n",
    "    # Export a queryable view od the stream\n",
    "    return stocktrades_stream_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(SIDE + '_view') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b70deb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create views of the buy and sell streams\n",
    "BUY_stream = generate_side_stream('BUY')\n",
    "SELL_stream = generate_side_stream('SELL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfedbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "|event_key|event_topic|     event_timestamp|quantity|price|symbol|account|userid|\n",
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1585|  140|  ZBZX| XYZ789|User_8|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    3309|  235|   ZVV| LMN456|User_8|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    4310|  519| ZWZZT| XYZ789|User_2|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1664|  602|  ZBZX| LMN456|User_4|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    3316|  611| ZWZZT| ABC123|User_6|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    2626|  829| ZWZZT| ABC123|User_1|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    4922|  381| ZXZZT| XYZ789|User_1|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|      34|  210| ZJZZT| LMN456|User_4|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    4664|  457| ZTEST| ABC123|User_8|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|      49|  923| ZWZZT| ABC123|User_8|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    3556|  882| ZJZZT| LMN456|User_7|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    3484|  369|   ZVV| LMN456|User_7|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1286|  583| ZTEST| ABC123|User_8|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    4106|  580| ZTEST| LMN456|User_2|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1525|  631| ZJZZT| ABC123|User_1|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    4724|  574|   ZVV| XYZ789|User_2|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1960|  331|   ZVV| ABC123|User_9|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    3998|  946|   ZVV| ABC123|User_2|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|     152|  336| ZTEST| ABC123|User_7|\n",
      "|     null| BUY_TRADES|2021-06-11 03:00:...|    1282|  340| ZVZZT| XYZ789|User_6|\n",
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show results (limit 20) of stream\n",
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT * FROM BUY_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4374e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "|event_key|event_topic|     event_timestamp|quantity|price|symbol|account|userid|\n",
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    1719|  453|  ZBZX| XYZ789|User_9|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    3029|  424|  ZBZX| XYZ789|User_5|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2420|  721| ZWZZT| LMN456|User_9|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2173|  352| ZWZZT| XYZ789|User_9|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2993|   10| ZJZZT| ABC123|User_8|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2448|  889| ZTEST| XYZ789|User_4|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|     189|  106| ZXZZT| ABC123|User_2|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    1366|  970| ZWZZT| XYZ789|User_7|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    3171|  189|  ZBZX| XYZ789|User_6|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    4241|  766| ZJZZT| XYZ789|User_1|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2583|  321| ZVZZT| XYZ789|User_5|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    3994|  787| ZWZZT| XYZ789|User_9|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    3820|   93| ZTEST| XYZ789|User_4|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2421|    8| ZWZZT| LMN456|User_1|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|     672|  703| ZVZZT| XYZ789|User_5|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|      75|  287| ZVZZT| LMN456|User_7|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    4030|  883| ZTEST| LMN456|User_2|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2005|  227| ZTEST| LMN456|User_3|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    2807|  188| ZTEST| LMN456|User_4|\n",
      "|     null|SELL_TRADES|2021-06-11 03:00:...|    3457|   13| ZWZZT| XYZ789|User_5|\n",
      "+---------+-----------+--------------------+--------+-----+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show results (limit 20) of stream\n",
    "clear_output(wait=True)\n",
    "display(spark.sql('SELECT * FROM SELL_view').show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33bfdcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the two streams\n",
    "BUY_stream.stop()\n",
    "SELL_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752071b",
   "metadata": {},
   "source": [
    "## Part 3b - Build 1 window stream with a watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a94ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the raw data data frame\n",
    "raw_stream, raw_stream_df = generate_stocktrades_stream(True)\n",
    "\n",
    "# Create parameters for the window stream\n",
    "window_duration = '60 seconds'\n",
    "slide_duration = '10 seconds'\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3556a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the windowed stream (this groups by symbol and then counts the numbers of trades in the window, quantity of shares traded and the average price traded)\n",
    "windowed_agg_df = raw_stream_df \\\n",
    "    .withWatermark('event_timestamp', '1 minutes') \\\n",
    "    .groupBy(F.window(raw_stream_df.event_timestamp, window_duration, slide_duration), raw_stream_df.symbol) \\\n",
    "    .agg(F.count('SYMBOL').alias('no_trades'), \\\n",
    "    F.sum('QUANTITY').alias('tot_quantity'), \\\n",
    "    F.avg('PRICE').alias('avg_price') \\\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f6fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the stream as a qeuryable view\n",
    "windowed_agg_stream = windowed_agg_df \\\n",
    "                        .writeStream \\\n",
    "                        .format(\"memory\") \\\n",
    "                        .outputMode(\"Complete\") \\\n",
    "                        .queryName(\"windowed_view\") \\\n",
    "                        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db127cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cd5815aa00a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM windowed_view'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    display(spark.sql('SELECT * FROM windowed_view').show())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "841f1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04d05d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_agg_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1e429",
   "metadata": {},
   "source": [
    "## Part 3c - Build at least 1 spark query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43ea1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrade_stream_df = generate_stocktrades_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e402d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from stocktrades_view WHERE price > 800\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920addf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|event_key|     event_topic|     event_timestamp|side|quantity|price|symbol|account|userid|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    4259|  965| ZJZZT| ABC123|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    4587|  915|   ZVV| LMN456|User_7|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    4050|  963| ZVZZT| ABC123|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    2279|  845|  ZBZX| XYZ789|User_2|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    3705|  866|   ZVV| ABC123|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    4997|  881| ZTEST| ABC123|User_6|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    4236|  813| ZJZZT| LMN456|User_8|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    2293|  971| ZJZZT| ABC123|User_2|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    3720|  906| ZJZZT| LMN456|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    3030|  925|   ZVV| LMN456|User_5|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    1827|  804| ZXZZT| XYZ789|User_3|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    4797|  974| ZJZZT| ABC123|User_2|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    1742|  804| ZJZZT| LMN456|User_4|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...|SELL|    3190|  982| ZVZZT| LMN456|User_4|\n",
      "|     null|STOCKTRADES_JSON|2021-06-11 03:02:...| BUY|    2849|  938| ZJZZT| ABC123|User_2|\n",
      "+---------+----------------+--------------------+----+--------+-----+------+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show results (limit 20) of stream\n",
    "clear_output(wait=True)\n",
    "display(spark.sql(query).show(20))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6110766",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrade_stream_df.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa6e9",
   "metadata": {},
   "source": [
    "## Part 3d - Export your spark queries into parquetsstocktrade_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30cb33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrade_stream_df, raw_stream_df = generate_stocktrades_stream(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6820da04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f6f1076cf10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stream_df.writeStream \\\n",
    "                .format(\"parquet\") \\\n",
    "                .option(\"header\", True) \\\n",
    "                .option(\"path\", \"../data/parquet_output\") \\\n",
    "                .option(\"checkpointLocation\", \"checkpoint/data\") \\\n",
    "                .outputMode(\"append\") \\\n",
    "                .trigger(once=True) \\\n",
    "                .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3be512de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktrade_stream_df.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e6f98",
   "metadata": {},
   "source": [
    "## Part 3e - build at least 1 visualisation which will be refreshed at regular interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c09873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3479bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_stream = generate_side_stream('BUY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72e1c1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2a974ae6e386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT quantity,price, symbol FROM BUY_view'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quantity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2457\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2459\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2460\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    df = spark.sql('SELECT quantity,price, symbol FROM BUY_view').toPandas()\n",
    "    plt.hist(df['quantity'] )\n",
    "    plt.pause(5)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b23f5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce161de",
   "metadata": {},
   "source": [
    "## Part 4 - Build ML model\n",
    "We believe it would be useful to predict whether a trade was a buy or sell trade based on the quantity, price account and stock code.\n",
    "\n",
    "### Read Data from Parquet Sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dab1f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFile = spark.read.option(\"mergeSchema\", \"true\").parquet(\"../data/parquet_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52bb727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------------+----+------------------+------------------+------+-------+------+\n",
      "|summary|event_key|     event_topic|side|          quantity|             price|symbol|account|userid|\n",
      "+-------+---------+----------------+----+------------------+------------------+------+-------+------+\n",
      "|  count|        0|            7640|7640|              7640|              7640|  7640|   7640|  7640|\n",
      "|   mean|     null|            null|null|2508.0336387434554|496.64829842931937|  null|   null|  null|\n",
      "| stddev|     null|            null|null| 1428.720525097279| 288.1620311483794|  null|   null|  null|\n",
      "|    min|     null|STOCKTRADES_JSON| BUY|                 1|                 5|  ZBZX| ABC123|User_1|\n",
      "|    max|     null|STOCKTRADES_JSON|SELL|              4999|               999| ZXZZT| XYZ789|User_9|\n",
      "+-------+---------+----------------+----+------------------+------------------+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquetFile.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8967c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['symbol','account','userid']\n",
    "cols = [\"side\",'quantity','price','symbol','account','userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1d36e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parquetFile.select(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f91808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f45b40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "for cat_col in cat_cols:\n",
    "    col_indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_ind\")\n",
    "    col_encoder = OneHotEncoder(inputCols=[f\"{cat_col}_ind\"], outputCols=[f\"{cat_col}_ohe\"])\n",
    "    stages += [col_indexer, col_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4622b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"quantity\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "030a99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_ohe = [f\"{cat_col}_ohe\" for cat_col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64d20f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "051e8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "32a9bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de23c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f7cd5",
   "metadata": {},
   "source": [
    "### Build X Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6781758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-------+------+\n",
      "|side|quantity|price|symbol|account|userid|\n",
      "+----+--------+-----+------+-------+------+\n",
      "| BUY|    3730|   69|   ZVV| XYZ789|User_8|\n",
      "|SELL|    1632|  985| ZXZZT| ABC123|User_3|\n",
      "| BUY|    2563|  969| ZWZZT| ABC123|User_4|\n",
      "| BUY|    2780|  945| ZXZZT| XYZ789|User_4|\n",
      "|SELL|    3460|  830| ZVZZT| XYZ789|User_6|\n",
      "+----+--------+-----+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb965754",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c06428b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f48f021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-------+------+----------+-------------+-----------+-------------+----------+-------------+--------------------+\n",
      "|side|quantity|price|symbol|account|userid|symbol_ind|   symbol_ohe|account_ind|  account_ohe|userid_ind|   userid_ohe|            features|\n",
      "+----+--------+-----+------+-------+------+----------+-------------+-----------+-------------+----------+-------------+--------------------+\n",
      "| BUY|    3730|   69|   ZVV| XYZ789|User_8|       5.0|(6,[5],[1.0])|        1.0|(2,[1],[1.0])|       3.0|(8,[3],[1.0])|(18,[5,7,11,16,17...|\n",
      "|SELL|    1632|  985| ZXZZT| ABC123|User_3|       2.0|(6,[2],[1.0])|        0.0|(2,[0],[1.0])|       0.0|(8,[0],[1.0])|(18,[2,6,8,16,17]...|\n",
      "| BUY|    2563|  969| ZWZZT| ABC123|User_4|       0.0|(6,[0],[1.0])|        0.0|(2,[0],[1.0])|       4.0|(8,[4],[1.0])|(18,[0,6,12,16,17...|\n",
      "| BUY|    2780|  945| ZXZZT| XYZ789|User_4|       2.0|(6,[2],[1.0])|        1.0|(2,[1],[1.0])|       4.0|(8,[4],[1.0])|(18,[2,7,12,16,17...|\n",
      "|SELL|    3460|  830| ZVZZT| XYZ789|User_6|       6.0|    (6,[],[])|        1.0|(2,[1],[1.0])|       5.0|(8,[5],[1.0])|(18,[7,13,16,17],...|\n",
      "+----+--------+-----+------+-------+------+----------+-------------+-----------+-------------+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96b27948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f5561355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['features','side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a444a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|side|\n",
      "+--------------------+----+\n",
      "|(18,[5,7,11,16,17...| BUY|\n",
      "|(18,[2,6,8,16,17]...|SELL|\n",
      "|(18,[0,6,12,16,17...| BUY|\n",
      "|(18,[2,7,12,16,17...| BUY|\n",
      "|(18,[7,13,16,17],...|SELL|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96541253",
   "metadata": {},
   "source": [
    "### Scale X Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb8f356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2821a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "xscalerModel = xscaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1c487440",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2722.save.\n: java.io.IOException: Path ../models/xscaler already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-84b82864bc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxscalerModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/xscaler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;34m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a string, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2722.save.\n: java.io.IOException: Path ../models/xscaler already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "xscalerModel.save(\"../models/xscaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b1f49b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xscalerModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "be9c552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+\n",
      "|            features|side|      scaledFeatures|\n",
      "+--------------------+----+--------------------+\n",
      "|(18,[5,7,11,16,17...| BUY|(18,[5,7,11,16,17...|\n",
      "|(18,[2,6,8,16,17]...|SELL|(18,[2,6,8,16,17]...|\n",
      "|(18,[0,6,12,16,17...| BUY|(18,[0,6,12,16,17...|\n",
      "|(18,[2,7,12,16,17...| BUY|(18,[2,7,12,16,17...|\n",
      "|(18,[7,13,16,17],...|SELL|(18,[7,13,16,17],...|\n",
      "+--------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb23d9",
   "metadata": {},
   "source": [
    "### Convert target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6028a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yencoder = StringIndexer(inputCol='side', outputCol=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e390ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coder = yencoder.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b4765823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = y_coder.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856abac",
   "metadata": {},
   "source": [
    "### Split into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "60d7c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.7,0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f959f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+------+\n",
      "|            features|side|      scaledFeatures|target|\n",
      "+--------------------+----+--------------------+------+\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...| BUY|(18,[0,6,9,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...| BUY|(18,[0,6,9,16,17]...|   1.0|\n",
      "+--------------------+----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cfd61917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+------+\n",
      "|            features|side|      scaledFeatures|target|\n",
      "+--------------------+----+--------------------+------+\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...| BUY|(18,[0,6,9,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...|SELL|(18,[0,6,9,16,17]...|   0.0|\n",
      "|(18,[0,6,9,16,17]...| BUY|(18,[0,6,9,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...| BUY|(18,[0,6,9,16,17]...|   1.0|\n",
      "|(18,[0,6,9,16,17]...|SELL|(18,[0,6,9,16,17]...|   0.0|\n",
      "+--------------------+----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c71cbe",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5e91a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "978ef365",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8,featuresCol='scaledFeatures', labelCol = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ce0aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513925d7",
   "metadata": {},
   "source": [
    "## Make predictions on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ebe6fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_dt = lrModel.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9c1a0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_dt = lrModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f916d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "70a01dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+------+--------------------+--------------------+----------+\n",
      "|            features|side|      scaledFeatures|target|       rawPrediction|         probability|prediction|\n",
      "+--------------------+----+--------------------+------+--------------------+--------------------+----------+\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|[0.01844390165925...|[0.50461084470675...|       0.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|[0.01844390165925...|[0.50461084470675...|       0.0|\n",
      "|(18,[0,6,8,16,17]...|SELL|(18,[0,6,8,16,17]...|   0.0|[0.01844390165925...|[0.50461084470675...|       0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|[0.01844390165925...|[0.50461084470675...|       0.0|\n",
      "|(18,[0,6,8,16,17]...| BUY|(18,[0,6,8,16,17]...|   1.0|[0.01844390165925...|[0.50461084470675...|       0.0|\n",
      "+--------------------+----+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds_dt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "09ce2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = test_preds_dt.rdd.map(lambda lp: (lp.prediction,float(lp.target)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "38ea24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e8b4ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2c4c8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "85919f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1dffae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1100.    0.]\n",
      " [1118.    0.]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6557d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
